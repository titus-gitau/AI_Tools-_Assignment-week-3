{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLN5HAgJXbSn",
        "outputId": "066ad061-ea05-48d4-904d-14325599d34c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All necessary libraries imported successfully!\n",
            "============================================================\n",
            "Dataset Information:\n",
            "Number of samples: 150\n",
            "Number of features: 4\n",
            "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Target names: ['setosa' 'versicolor' 'virginica']\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   species  \n",
            "0        0  \n",
            "1        0  \n",
            "2        0  \n",
            "3        0  \n",
            "4        0  \n",
            "\n",
            "Basic statistics of the features:\n",
            "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
            "count         150.000000        150.000000         150.000000   \n",
            "mean            5.843333          3.057333           3.758000   \n",
            "std             0.828066          0.435866           1.765298   \n",
            "min             4.300000          2.000000           1.000000   \n",
            "25%             5.100000          2.800000           1.600000   \n",
            "50%             5.800000          3.000000           4.350000   \n",
            "75%             6.400000          3.300000           5.100000   \n",
            "max             7.900000          4.400000           6.900000   \n",
            "\n",
            "       petal width (cm)     species  \n",
            "count        150.000000  150.000000  \n",
            "mean           1.199333    1.000000  \n",
            "std            0.762238    0.819232  \n",
            "min            0.100000    0.000000  \n",
            "25%            0.300000    0.000000  \n",
            "50%            1.300000    1.000000  \n",
            "75%            1.800000    2.000000  \n",
            "max            2.500000    2.000000  \n",
            "\n",
            "Features (X) shape: (150, 4)\n",
            "Target (y) shape: (150,)\n",
            "\n",
            "Label Encoding Mapping:\n",
            "0 -> setosa\n",
            "1 -> versicolor\n",
            "2 -> virginica\n",
            "\n",
            "Sample of original vs encoded species:\n",
            "   species  species_encoded\n",
            "0        0                0\n",
            "1        0                0\n",
            "2        0                0\n",
            "3        0                0\n",
            "4        0                0\n",
            "5        0                0\n",
            "6        0                0\n",
            "7        0                0\n",
            "8        0                0\n",
            "9        0                0\n",
            "\n",
            "Data splitting completed:\n",
            "Training set size: 120 samples (80.0%)\n",
            "Testing set size: 30 samples (20.0%)\n",
            "\n",
            "Species distribution in training set:\n",
            "  setosa: 40 samples\n",
            "  versicolor: 41 samples\n",
            "  virginica: 39 samples\n",
            "\n",
            "Species distribution in test set:\n",
            "  setosa: 10 samples\n",
            "  versicolor: 9 samples\n",
            "  virginica: 11 samples\n",
            "\n",
            "Decision Tree Classifier initialized with default parameters:\n",
            "Criterion: gini\n",
            "Max depth: None\n",
            "Min samples split: 2\n",
            "\n",
            "Training the model...\n",
            "Model training completed!\n",
            "\n",
            "Making predictions on test set...\n",
            "Predictions completed!\n",
            "\n",
            "MODEL EVALUATION RESULTS:\n",
            "========================================\n",
            "Accuracy: 1.0000 (100.00%)\n",
            "Precision (macro-average): 1.0000 (100.00%)\n",
            "Recall (macro-average): 1.0000 (100.00%)\n",
            "\n",
            "CLASSIFICATION REPORT:\n",
            "========================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa     1.0000    1.0000    1.0000        10\n",
            "  versicolor     1.0000    1.0000    1.0000         9\n",
            "   virginica     1.0000    1.0000    1.0000        11\n",
            "\n",
            "    accuracy                         1.0000        30\n",
            "   macro avg     1.0000    1.0000    1.0000        30\n",
            "weighted avg     1.0000    1.0000    1.0000        30\n",
            "\n",
            "\n",
            "FEATURE IMPORTANCE:\n",
            "========================================\n",
            "sepal length (cm): 0.0000 (0.00%)\n",
            "sepal width (cm): 0.0167 (1.67%)\n",
            "petal length (cm): 0.9061 (90.61%)\n",
            "petal width (cm): 0.0772 (7.72%)\n",
            "\n",
            "Most important feature for classification: petal length (cm)\n",
            "Its importance score: 0.9061\n",
            "\n",
            "SAMPLE PREDICTIONS:\n",
            "========================================\n",
            "Actual vs Predicted species (first 10 test samples):\n",
            "Sample 1: Actual = versicolor, Predicted = versicolor\n",
            "Sample 2: Actual = setosa, Predicted = setosa\n",
            "Sample 3: Actual = virginica, Predicted = virginica\n",
            "Sample 4: Actual = versicolor, Predicted = versicolor\n",
            "Sample 5: Actual = versicolor, Predicted = versicolor\n",
            "Sample 6: Actual = setosa, Predicted = setosa\n",
            "Sample 7: Actual = versicolor, Predicted = versicolor\n",
            "Sample 8: Actual = virginica, Predicted = virginica\n",
            "Sample 9: Actual = versicolor, Predicted = versicolor\n",
            "Sample 10: Actual = versicolor, Predicted = versicolor\n",
            "\n",
            "============================================================\n",
            "SCRIPT EXECUTION COMPLETED SUCCESSFULLY!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Iris Species Classification using Decision Tree Classifier\n",
        "\n",
        "This script demonstrates a complete machine learning workflow using Scikit-learn\n",
        "to classify iris species based on their sepal and petal measurements.\n",
        "\n",
        "Dataset: Iris Species Dataset (built-in sklearn dataset)\n",
        "Model: Decision Tree Classifier\n",
        "Features: Sepal length, sepal width, petal length, petal width\n",
        "Target: Species (setosa, versicolor, virginica)\n",
        "\n",
        "Author: AI Assistant\n",
        "Date: 2025-10-16\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 1: IMPORTS AND SETUP\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "\n",
        "print(\"All necessary libraries imported successfully!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 2: DATA LOADING AND EXPLORATION\n",
        "# =============================================================================\n",
        "\n",
        "# Load the Iris dataset from sklearn\n",
        "iris_data = load_iris()\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"Number of samples: {len(iris_data.data)}\")\n",
        "print(f\"Number of features: {len(iris_data.feature_names)}\")\n",
        "print(f\"Feature names: {iris_data.feature_names}\")\n",
        "print(f\"Target names: {iris_data.target_names}\")\n",
        "print()\n",
        "\n",
        "# Convert the data into a Pandas DataFrame for better handling\n",
        "# Create DataFrame with feature data\n",
        "iris_df = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
        "\n",
        "# Add target variable to DataFrame\n",
        "iris_df['species'] = iris_data.target\n",
        "\n",
        "# Display first few rows to understand the data structure\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(iris_df.head())\n",
        "print()\n",
        "\n",
        "# Display basic statistics\n",
        "print(\"Basic statistics of the features:\")\n",
        "print(iris_df.describe())\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 3: DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "# Separate features (X) from target (y)\n",
        "# Features are the measurements (sepal length, sepal width, petal length, petal width)\n",
        "# Target is the species classification\n",
        "X = iris_df.drop('species', axis=1)  # Features\n",
        "y = iris_df['species']  # Target\n",
        "\n",
        "print(\"Features (X) shape:\", X.shape)\n",
        "print(\"Target (y) shape:\", y.shape)\n",
        "print()\n",
        "\n",
        "# Apply LabelEncoder to convert species names to numerical labels\n",
        "# This is necessary because sklearn models work with numerical data\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder and transform the target variable\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Display the mapping between original species names and encoded labels\n",
        "print(\"Label Encoding Mapping:\")\n",
        "for i, species in enumerate(iris_data.target_names):\n",
        "    print(f\"{i} -> {species}\")\n",
        "print()\n",
        "\n",
        "# Update the DataFrame with encoded target for consistency\n",
        "iris_df['species_encoded'] = y_encoded\n",
        "\n",
        "# Display sample of original vs encoded species\n",
        "print(\"Sample of original vs encoded species:\")\n",
        "print(iris_df[['species', 'species_encoded']].head(10))\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 4: DATA SPLITTING\n",
        "# =============================================================================\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# Using 80% for training and 20% for testing (standard practice)\n",
        "# random_state ensures reproducible results\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Data splitting completed:\")\n",
        "print(f\"Training set size: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Testing set size: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "print()\n",
        "\n",
        "# Display the distribution of species in training and test sets\n",
        "print(\"Species distribution in training set:\")\n",
        "train_species_dist = pd.Series(y_train).value_counts().sort_index()\n",
        "for label, count in train_species_dist.items():\n",
        "    species_name = iris_data.target_names[label]\n",
        "    print(f\"  {species_name}: {count} samples\")\n",
        "\n",
        "print(\"\\nSpecies distribution in test set:\")\n",
        "test_species_dist = pd.Series(y_test).value_counts().sort_index()\n",
        "for label, count in test_species_dist.items():\n",
        "    species_name = iris_data.target_names[label]\n",
        "    print(f\"  {species_name}: {count} samples\")\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 5: MODEL TRAINING\n",
        "# =============================================================================\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "# Using default parameters for simplicity, but these can be tuned for better performance\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "print(\"Decision Tree Classifier initialized with default parameters:\")\n",
        "print(f\"Criterion: {decision_tree.criterion}\")\n",
        "print(f\"Max depth: {decision_tree.max_depth}\")\n",
        "print(f\"Min samples split: {decision_tree.min_samples_split}\")\n",
        "print()\n",
        "\n",
        "# Train the model on the training data\n",
        "print(\"Training the model...\")\n",
        "decision_tree.fit(X_train, y_train)\n",
        "print(\"Model training completed!\")\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 6: MODEL PREDICTION AND EVALUATION\n",
        "# =============================================================================\n",
        "\n",
        "# Make predictions on the test set\n",
        "print(\"Making predictions on test set...\")\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "print(\"Predictions completed!\")\n",
        "print()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# Display the results\n",
        "print(\"MODEL EVALUATION RESULTS:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"Precision (macro-average): {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"Recall (macro-average): {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print()\n",
        "\n",
        "# Display detailed classification report\n",
        "print(\"CLASSIFICATION REPORT:\")\n",
        "print(\"=\" * 40)\n",
        "print(classification_report(\n",
        "    y_test, y_pred,\n",
        "    target_names=iris_data.target_names,\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 7: ADDITIONAL ANALYSIS (OPTIONAL)\n",
        "# =============================================================================\n",
        "\n",
        "# Display feature importance (Decision Trees provide this useful information)\n",
        "print(\"\\nFEATURE IMPORTANCE:\")\n",
        "print(\"=\" * 40)\n",
        "feature_importance = decision_tree.feature_importances_\n",
        "for feature, importance in zip(iris_data.feature_names, feature_importance):\n",
        "    print(f\"{feature}: {importance:.4f} ({importance*100:.2f}%)\")\n",
        "\n",
        "# Find the most important feature\n",
        "most_important_idx = np.argmax(feature_importance)\n",
        "most_important_feature = iris_data.feature_names[most_important_idx]\n",
        "print(f\"\\nMost important feature for classification: {most_important_feature}\")\n",
        "print(f\"Its importance score: {feature_importance[most_important_idx]:.4f}\")\n",
        "\n",
        "# Display some sample predictions with actual vs predicted\n",
        "print(\"\\nSAMPLE PREDICTIONS:\")\n",
        "print(\"=\" * 40)\n",
        "print(\"Actual vs Predicted species (first 10 test samples):\")\n",
        "for i in range(min(10, len(y_test))):\n",
        "    actual_species = iris_data.target_names[y_test[i]]\n",
        "    predicted_species = iris_data.target_names[y_pred[i]]\n",
        "    print(f\"Sample {i+1}: Actual = {actual_species}, Predicted = {predicted_species}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SCRIPT EXECUTION COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ]
}